colnames(awesome) <- c("Bayes n=100","Bayes n=200","Bayes n=500", "Bayes n=1000","Logit n=100","Logit n=200","Logit n=500","Logit n=1000")
awesome
row.names(awesome) <- c("mean_error","sd_error")
awesome
library(caret)
library(e1071)
kk <- c()
jj <- 1
for(j in 1:100){
m1 <- multivariate(n = 100)
m1 <- as.data.frame(m1)
m1[,2] = as.factor(m1[,2])
df <- m1[sample(nrow(m1)),]
folds <- cut(seq(1,nrow(df)),breaks=10,labels=FALSE)
for(i in 1:10){
testIndexes <- which(folds==i,arr.ind=TRUE)
testData    <- df[testIndexes, ]
trainData   <- df[-testIndexes, ]
trainControl(method="repeatedcv",number=10, repeats=100)
set.seed(1234)
knn_fit <- train(V2~V1, data=trainData, method="knn", tuneLength=10)
abc <- predict(knn_fit,newdata=testData)
kk[jj] <- length(which(testData[,2]!=abc))/length(abc)
jj <- jj + 1
}
}
library(caret)
library(e1071)
kk <- c()
jj <- 1
for(j in 1:100){
m1 <- multivariate(n = 100)
m1 <- as.data.frame(m1)
m1[,2] = as.factor(m1[,2])
df <- m1[sample(nrow(m1)),]
folds <- cut(seq(1,nrow(df)),breaks=10,labels=FALSE)
for(i in 1:10){
testIndexes <- which(folds==i,arr.ind=TRUE)
testData    <- df[testIndexes, ]
trainData   <- df[-testIndexes, ]
trainControl(method="repeatedcv",number=10, repeats=100)
set.seed(1234)
knn_fit <- train(V2~V1, data=trainData, method="knn", tuneLength=10)
abc <- predict(knn_fit,newdata=testData)
kk[jj] <- length(which(testData[,2]!=abc))/length(abc)
jj <- jj + 1
}
}
library(caret)
library(e1071)
kk <- c()
jj <- 1
for(j in 1:100){
m1 <- multivariate(n = 100)
m1 <- as.data.frame(m1)
m1[,2] = as.factor(m1[,2])
df <- m1[sample(nrow(m1)),]
folds <- cut(seq(1,nrow(df)),breaks=10,labels=FALSE)
for(i in 1:10){
testIndexes <- which(folds==i,arr.ind=TRUE)
testData    <- df[testIndexes, ]
trainData   <- df[-testIndexes, ]
trainControl(method="repeatedcv",number=10, repeats=100)
set.seed(1234)
knn_fit <- train(V2~V1, data=trainData, method="knn")
abc <- predict(knn_fit,newdata=testData)
kk[jj] <- length(which(testData[,2]!=abc))/length(abc)
jj <- jj + 1
}
}
one[1]
rep(c(one[1],two[1],three[1],four[1],five[1],six[1],seven[1],eight[1]),each=1000)
mean <- cbind(rep(c(one[1],two[1],three[1],four[1],five[1],six[1],seven[1],eight[1]),each=1000))
mean
sd <- cbind(rep(c(one[2],two[2],three[2],four[2],five[2],six[2],seven[2],eight[2]),each=1000))
sd
sd1 <- cbind(rep(c(one[2],two[2],three[2],four[2],five[2],six[2],seven[2],eight[2]),each=1000))
mean1 <- cbind(rep(c(one[1],two[1],three[1],four[1],five[1],six[1],seven[1],eight[1]),each=1000))
size <- c(rep(c("n=100","n=200","n=500","n=1000"),each=1000),rep(c("n=100","n=200","n=500","n=1000"),each=1000))
model <- c(rep("Bayes",each=4000),rep("Logistic Regression",each=4000))
errors <- as.data.frame(as.numeric(trials))
errors$sample_size <- size
errors$model <- model
errors$sd <- sd1
errors$mean <- mean1
class(errors$mean)
errors$mean
class(errors$sd)
as.integer(sd1)
as.numeric(sd1)
as.numeric(mean1)
as.numeric(sd1)
ggplot(errors, aes(x=as.factor(sample_size), y=(error_rates), fill=model)) +
geom_boxplot() +
xlab("Sample Size") +
ylab("Error Rates")  +
stat_summary(fun.y=mean, geom="point", size=2) +
stat_summary(fun.data = mean_se, geom = "errorbar")
names(errors) <- c("error_rates","sample_size","model")
ggplot(errors, aes(x=as.factor(sample_size), y=(error_rates), fill=model)) +
geom_boxplot() +
xlab("Sample Size") +
ylab("Error Rates")  +
stat_summary(fun.y=mean, geom="point", size=2) +
stat_summary(fun.data = mean_se, geom = "errorbar")
knitr::include_graphics("/Users/chris/Desktop/Screen Shot 2018-10-25 at 10.11.37 PM.png")
knitr::include_graphics("/Users/chris/Desktop/Screen Shot 2018-10-25 at 9.53.48 PM.png")
#K Nearest Neighbors
#n=100
library(caret)
library(e1071)
kk <- c()
jj <- 1
for(j in 1:100){
m1 <- multivariate(n = 100)
m1 <- as.data.frame(m1)
m1[,2] = as.factor(m1[,2])
df <- m1[sample(nrow(m1)),]
folds <- cut(seq(1,nrow(df)),breaks=10,labels=FALSE)
for(i in 1:10){
testIndexes <- which(folds==i,arr.ind=TRUE)
testData    <- df[testIndexes, ]
trainData   <- df[-testIndexes, ]
trainControl(method="repeatedcv",number=10, repeats=100)
set.seed(1234)
knn_fit <- train(V2~V1, data=trainData, method="knn")
abc <- predict(knn_fit,newdata=testData)
kk[jj] <- length(which(testData[,2]!=abc))/length(abc)
jj <- jj + 1
}
}
mean(kk)=.18983
sd(kk)=.137
eight <- cbind(.18983,.137)
#n=200
library(caret)
library(e1071)
kk2 <- c()
jj2 <- 1
for(j in 1:100){
m1 <- multivariate(n = 200)
m1 <- as.data.frame(m1)
m1[,2] = as.factor(m1[,2])
df <- m1[sample(nrow(m1)),]
folds <- cut(seq(1,nrow(df)),breaks=10,labels=FALSE)
for(i in 1:10){
testIndexes <- which(folds==i,arr.ind=TRUE)
testData    <- df[testIndexes, ]
trainData   <- df[-testIndexes, ]
trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(1234)
knn_fit2 <- train(V2~V1, data=trainData, method="knn")
abc <- predict(knn_fit2,newdata=testData)
kk2[jj] <- length(which(testData[,2]!=abc))/length(abc)
jj2 <- jj + 1
}
}
nine <- cbind(.18983,.137)
#n=500
library(caret)
library(e1071)
kk3 <- c()
jj3 <- 1
for(j in 1:100){
m1 <- multivariate(n = 500)
m1 <- as.data.frame(m1)
m1[,2] = as.factor(m1[,2])
df <- m1[sample(nrow(m1)),]
folds <- cut(seq(1,nrow(df)),breaks=10,labels=FALSE)
for(i in 1:10){
testIndexes <- which(folds==i,arr.ind=TRUE)
testData    <- df[testIndexes, ]
trainData   <- df[-testIndexes, ]
trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(1234)
knn_fit3 <- train(V2~V1, data=trainData, method="knn")
abc <- predict(knn_fit3,newdata=testData)
kk3[jj] <- length(which(testData[,2]!=abc))/length(abc)
jj3 <- jj + 1
}
}
ten <- cbind(.18983,.137)
#n=1000
library(caret)
library(e1071)
kk4 <- c()
jj4 <- 1
for(j in 1:100){
m1 <- multivariate(n = 1000)
m1 <- as.data.frame(m1)
m1[,2] = as.factor(m1[,2])
df <- m1[sample(nrow(m1)),]
folds <- cut(seq(1,nrow(df)),breaks=10,labels=FALSE)
for(i in 1:10){
testIndexes <- which(folds==i,arr.ind=TRUE)
testData    <- df[testIndexes, ]
trainData   <- df[-testIndexes, ]
trainControl(method="repeatedcv",number=10, repeats=3)
set.seed(1234)
knn_fit4 <- train(V2~V1, data=trainData, method="knn")
abc <- predict(knn_fit4,newdata=testData)
kk4[jj] <- length(which(testData[,2]!=abc))/length(abc)
jj4 <- jj + 1
}
}
kk
kk2
kk3
kk4
nine
awesome <- matrix(c(one,two,three,four,five,six,seven,eight,nine),nrow=2)
row.names(awesome) <- c("mean_error","sd_error")
colnames(awesome) <- c("Bayes n=100","Bayes n=200","Bayes n=500", "Bayes n=1000","Logit n=100","Logit n=200","Logit n=500","Logit n=1000", "K-NN N=100")
awesome
pp <- kk
library(caret)
library(e1071)
kk <- c()
jj <- 1
for(j in 1:100){
m1 <- multivariate(n = 200)
m1 <- as.data.frame(m1)
m1[,2] = as.factor(m1[,2])
df <- m1[sample(nrow(m1)),]
folds <- cut(seq(1,nrow(df)),breaks=10,labels=FALSE)
for(i in 1:10){
testIndexes <- which(folds==i,arr.ind=TRUE)
testData    <- df[testIndexes, ]
trainData   <- df[-testIndexes, ]
trainControl(method="repeatedcv",number=10, repeats=100)
set.seed(1234)
knn_fit <- train(V2~V1, data=trainData, method="knn")
abc <- predict(knn_fit,newdata=testData)
kk[jj] <- length(which(testData[,2]!=abc))/length(abc)
jj <- jj + 1
}
}
kk
oo <- kk
library(caret)
library(e1071)
kk <- c()
jj <- 1
for(j in 1:100){
m1 <- multivariate(n = 500)
m1 <- as.data.frame(m1)
m1[,2] = as.factor(m1[,2])
df <- m1[sample(nrow(m1)),]
folds <- cut(seq(1,nrow(df)),breaks=10,labels=FALSE)
for(i in 1:10){
testIndexes <- which(folds==i,arr.ind=TRUE)
testData    <- df[testIndexes, ]
trainData   <- df[-testIndexes, ]
trainControl(method="repeatedcv",number=10, repeats=100)
set.seed(1234)
knn_fit <- train(V2~V1, data=trainData, method="knn")
abc <- predict(knn_fit,newdata=testData)
kk[jj] <- length(which(testData[,2]!=abc))/length(abc)
jj <- jj + 1
}
}
dd <- kk
ten <- cbind(mean(oo),sd(oo))
eleven <- cbind(mean(dd),sd(dd))
awesome <- matrix(c(one,two,three,four,five,six,seven,eight,nine,ten,eleven),nrow=2)
row.names(awesome) <- c("mean_error","sd_error")
colnames(awesome) <- c("Bayes n=100","Bayes n=200","Bayes n=500", "Bayes n=1000","Logit n=100","Logit n=200","Logit n=500","Logit n=1000", "K-NN N=100", "K-NN N=200", "K-NN N=500")
trials <- c(ab,bb,cc,dd,result,result11,result3,result4,kk,oo,pp)
sd1 <- cbind(rep(c(one[2],two[2],three[2],four[2],five[2],six[2],seven[2],eight[2],nine[2],ten[2],eleven[2]),each=1000))
mean1 <- cbind(rep(c(one[1],two[1],three[1],four[1],five[1],six[1],seven[1],eight[1],nine[1],ten[1],eleven[1]),each=1000))
size <- c(rep(c("n=100","n=200","n=500","n=1000"),each=1000),rep(c("n=100","n=200","n=500","n=1000"),each=1000),rep(c("n=100","n=200","n=500"),each=1000))
model <- c(rep("Bayes",each=4000),rep("Logistic Regression",each=4000),rep("K-NN",each=3000))
errors <- as.data.frame(as.numeric(trials))
errors$sample_size <- size
errors$model <- model
errors$sd <- as.numeric(sd1)
errors$mean <- as.numeric(mean1)
names(errors) <- c("error_rates","sample_size","model")
ggplot(errors, aes(x=as.factor(sample_size), y=(error_rates), fill=model)) +
geom_boxplot() +
xlab("Sample Size") +
ylab("Error Rates")  +
stat_summary(fun.y=mean, geom="point", size=2) +
stat_summary(fun.data = mean_se, geom = "errorbar")
awesome
library(caret)
library(e1071)
kk <- c()
jj <- 1
for(j in 1:100){
m1 <- multivariate(n = 1000)
m1 <- as.data.frame(m1)
m1[,2] = as.factor(m1[,2])
df <- m1[sample(nrow(m1)),]
folds <- cut(seq(1,nrow(df)),breaks=10,labels=FALSE)
for(i in 1:10){
testIndexes <- which(folds==i,arr.ind=TRUE)
testData    <- df[testIndexes, ]
trainData   <- df[-testIndexes, ]
trainControl(method="repeatedcv",number=10, repeats=100)
set.seed(1234)
knn_fit <- train(V2~V1, data=trainData, method="knn")
abc <- predict(knn_fit,newdata=testData)
kk[jj] <- length(which(testData[,2]!=abc))/length(abc)
jj <- jj + 1
}
}
knitr::include_graphics("/Users/chris/Desktop/Screen Shot 2018-10-26 at 7.30.02 AM.png")
knitr::include_graphics("/Users/chris/Desktop/Screen Shot 2018-10-26 at 7.29.47 AM.png")
rf_viz <-
function(rfprep,
input = TRUE,
imp = TRUE,
cmd = TRUE,
hl_color = "orange") {
tcl('set', '::loon::Options(select-color)', hl_color)
#This is to pass the CRAN checks
issa <- NULL
rm(issa)
idsa <- NULL
rm(idsa)
cmdxyz <- NULL
rm(cmdxyz)
cmdxyz <- NULL
rm(cmdxyz)
inputOnly <- FALSE
impOnly <- FALSE
cmdOnly <- FALSE
if(input == TRUE & imp == FALSE & cmd == FALSE) {
inputOnly <- TRUE
} else {
if(input == FALSE & imp == TRUE & cmd == FALSE) {
impOnly <- TRUE
} else {
if(input == FALSE & imp == FALSE & cmd == TRUE) {
cmdOnly <- TRUE
}
}
}
tt <- tktoplevel()
customInspector <- FALSE
if(inputOnly == TRUE | impOnly == TRUE | cmdOnly == TRUE) customInspector <- TRUE
#All three plots, the input data, local importance scores, and cmd scaled proximities
if (input == TRUE) {
#Input Serial Axes Plot
idsa <- l_serialaxes(
parent = tt,
rfprep$x,
linkingGroup = nrow(rfprep$x),
axesLayout = "parallel",
scaling = "variable",
title = "Input Data",
color = rfprep$y,
useLoonInspector = !customInspector
)
}
if (imp == TRUE) {
#Local Importance Score Plots
#Prepare the Local Importance Scores for the plot
xx <- as.data.frame(rfprep$rf$localImportance)
yy <- t(xx)
zz <- as.data.frame(yy)
issa <-
l_serialaxes(
parent = tt,
data = zz,
linkingGroup = nrow(rfprep$x),
axesLayout = "parallel",
scaling = "variable",
title = "Local Importance Scores",
useLoonInspector = !customInspector,
color = rfprep$y
)
}
if (cmd == TRUE) {
#Metric Multidimensional Scaling Proximities
#Obtain the CMD scaled proximities in preparation for plot
rf.mds <- cmdscale(1 - rfprep$rf$proximity, eig = TRUE, k = 3)
cmdxyz <-
l_plot(
parent = tt,
rf.mds$points,
linkingGroup = nrow(rfprep$x),
title = "Metric Multidimensional Scaling Proximities",
useLoonInspector = !customInspector,
color = rfprep$y,
xlabel = "",
ylabel = ""
)
}
#Setting up the viewing grid for the plots
#All plots
if (input == TRUE & imp == TRUE & cmd == TRUE) {
tkgrid(idsa,
row = 0,
column = 0,
sticky = "nesw")
tkgrid(issa,
row = 0,
column = 1,
sticky = "nesw")
tkgrid(cmdxyz,
row = 1,
column = 0,
sticky = "nesw")
}
if (input == TRUE && imp == TRUE && cmd == FALSE) {
tkgrid(idsa,
row = 0,
column = 0,
sticky = "nesw")
tkgrid(issa,
row = 1,
column = 0,
sticky = "nesw")
}
#Input data and CMD scaling proximities plots
if (input == TRUE & imp == FALSE & cmd == TRUE) {
tkgrid(idsa,
row = 0,
column = 0,
sticky = "nesw")
tkgrid(cmdxyz,
row = 1,
column = 0,
sticky = "nesw")
}
#Local Importance Score and CMD Proximities Plots
if (input == FALSE & imp == TRUE & cmd == TRUE) {
tkgrid(issa,
row = 0,
column = 0,
sticky = "nesw")
tkgrid(cmdxyz,
row = 1,
column = 0,
sticky = "nesw")
}
tkgrid.columnconfigure(tt, 0, weight = 1)
tkgrid.columnconfigure(tt, 1, weight = 1)
tkgrid.rowconfigure(tt, 0, weight = 1)
#Input Data Plot
if (inputOnly == TRUE) {
tkpack(idsa,
side = "left",
fill = "both",
expand = TRUE)
## Add a custom inspector (no layers)
f <- tkframe(tt)
ai <- l_serialaxes_inspector(parent = f, activewidget = idsa)
tkpack(f, side = "right", anchor = "ne")
tkpack(ai, side = "top", fill = "x")
}
#Local Importance Score Plot
if (impOnly == TRUE) {
tkpack(issa,
side = "left",
fill = "both",
expand = TRUE)
## Add a custom inspector (no layers)
f <- tkframe(tt)
ai <- l_serialaxes_inspector(parent = f, activewidget = issa)
tkpack(f, side = "right", anchor = "ne")
tkpack(ai, side = "top", fill = "x")
}
#CMD Scaling Proximities Plot
if (cmdOnly == TRUE) {
tkpack(
cmdxyz,
side = "left",
fill = "both",
expand = TRUE
)
## Add a custom inspector (no layers)
f <- tkframe(tt)
lf <- tkwidget(f, "labelframe", text = "Worldview")
wv <- l_worldview(parent = lf, activewidget = cmdxyz)
tkconfigure(paste(wv, ".canvas", sep = ""),
width = 50,
height = 160)
ai <-
l_plot_inspector_analysis(parent = f, activewidget = cmdxyz)
tkpack(f, side = "right", anchor = "ne")
tkpack(lf, side = "top", fill = "x")
tkpack(wv, side = "top", fill = "x")
tkpack(ai, side = "top", fill = "x")
}
if(cmd) cmdxyz else if(imp) issa else idsa
}
rf_prep <- function(x, y,...){
rf <-
randomForest(x,
y,
localImp = TRUE,
proximity = TRUE,
...)
return(list(rf = rf, x = x, y = y))
}
rfprep_glass <- rf_prep(x=glass[,-10], y=as.factor(glass[, 10]), seed=2894)
library(randomForest)
rf_prep(x=glass[,-10], y=as.factor(glass[, 10]), seed=2894)
rfprep_glass <- rf_prep(x=glass[,-10], y=as.factor(glass[, 10]), seed=2894)
rfglass <- rf_viz(rfprep_glass)
library(loon)
rfglass <- rf_viz(rfprep_glass)
setwd("~/Library/Mobile Documents/com~apple~CloudDocs/Chris USU/Master's Thesis Work/Final/rfviz")
library(devtools)
check()
document()
check()
build()
document()
